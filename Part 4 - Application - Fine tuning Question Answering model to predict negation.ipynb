{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1cf586e",
   "metadata": {},
   "source": [
    "# ABOUT:\n",
    "- this notebook further trains a fine-tuned Question Answering Model to detect negation span\n",
    "    - e.g \"It has a well thought out design and it is clean but it certainly feels a bit hollow and fake.\"\n",
    "    - the model is trained to predict \"but\" as the negation span\n",
    "    - e.g \"I love food\"\n",
    "    - the model also predicts no span if there are no negation found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd50231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint  = \"deepset/roberta-base-squad2\"\n",
    "max_length = 30\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329443f",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a2d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 3\\Sem 1\\CZ4045 Natural Language Processing\\Assignment 1\\local\\data\\answers.json\"\n",
    "with open(path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e571297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    is_impossible = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if qa['is_impossible']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append({'text': [],'answer_start': []})\n",
    "                    is_impossible.append(qa['is_impossible'])\n",
    "                else:\n",
    "                    for answer in qa['answers']:\n",
    "                        contexts.append(context)\n",
    "                        questions.append(question)\n",
    "                        answer['answer_start']  = [answer['answer_start']]\n",
    "                        answer['text']  = [answer['text']]\n",
    "                        answers.append(answer)\n",
    "                        is_impossible.append(qa['is_impossible'])\n",
    "    return contexts, questions, answers, is_impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8475d59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers', 'is_impossible'],\n",
       "    num_rows: 466\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "dataset = pd.DataFrame(dict(zip([\"context\", \"question\", \"answers\", \"is_impossible\"],  read_squad(path))))\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064c6e4",
   "metadata": {},
   "source": [
    "#### some helper functions:\n",
    "- read_squad: reads squad format data\n",
    "- show_random_elements: shows show samples in a Dataset object\n",
    "- prepare_train_features: \n",
    "    - tokenizes dataset \n",
    "    - prepares data as a Question Answering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badda8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "def show_random_elements(dataset, num_examples = 10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee79f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        # stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",                                                                                    \n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497f4ec",
   "metadata": {},
   "source": [
    "#### original dataset in SQUAD format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d904a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I should also say that even though the sale was done about two months ago... Darlene still had her hands in everything helping to ensure we were taken care of!!</td>\n",
       "      <td>negation</td>\n",
       "      <td>{'answer_category': None, 'answer_id': None, 'answer_start': [], 'document_id': None, 'question_id': None, 'text': []}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has a well thought out design and it is clean but it certainly feels a bit hollow and fake.</td>\n",
       "      <td>negation</td>\n",
       "      <td>{'answer_category': None, 'answer_id': 191675, 'answer_start': [49], 'document_id': 245424, 'question_id': 124928, 'text': ['but']}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If these problems remain unacknowledged and unaddressed, the country may lose its predominance and endanger its security.\\tCopy \\n</td>\n",
       "      <td>negation</td>\n",
       "      <td>{'answer_category': None, 'answer_id': 192580, 'answer_start': [25], 'document_id': 260367, 'question_id': 124928, 'text': ['unacknowledged']}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So pretty much at the cash out, the server was debating why I didn't follow up with him and in my mind I was like \"uhhh, I know your dirty secret of how you cover things up so...\" pretty much it confirmed a lot of my experiences before at this location.</td>\n",
       "      <td>negation</td>\n",
       "      <td>{'answer_category': None, 'answer_id': 191663, 'answer_start': [62], 'document_id': 245412, 'question_id': 124928, 'text': ['didn't']}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impulsiveness, impatience, senseless rebellion, and extravagance are the traits that so often undermine their work and dreams.\\tCopy \\n</td>\n",
       "      <td>negation</td>\n",
       "      <td>{'answer_category': None, 'answer_id': 192654, 'answer_start': [0], 'document_id': 260432, 'question_id': 124928, 'text': ['Impulsiveness']}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7f70d",
   "metadata": {},
   "source": [
    "## AutoTokenizer\n",
    "- tokenizes sentences into subwords/words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfae504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0850524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 120\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict(prepare_train_features(dataset))\n",
    "dataset = dataset.train_test_split(0.2, seed = 0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3818edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 120\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263a374",
   "metadata": {},
   "source": [
    "#### Question Answering dataset\n",
    "- model takes \"input_ids\" as input and outputs \"start_positions\" and \"end_positions\"\n",
    "- if there are no negation, model needs to predict token index 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edeeddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 23156, 1258, 2, 2, 1106, 47, 214, 2600, 42, 47, 214, 1153, 608, 5, 6089, 276, 631, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 23156, 1258, 2, 2, 9497, 33, 36939, 196, 4905, 8, 156, 33424, 1635, 14, 32, 12030, 4, 50117, 48233, 1437, 50118, 2, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 23156, 1258, 2, 2, 170, 33, 7154, 450, 143, 3250, 101, 2431, 4, 50118, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 23156, 1258, 2, 2, 18, 77, 38, 554, 21252, 5, 647, 165, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 23156, 1258, 2, 2, 100, 269, 1034, 5, 813, 8, 1945, 1516, 1058, 11, 2111, 544, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"],5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef4aec",
   "metadata": {},
   "source": [
    "#### Format of input\n",
    "- the question asked to the model is \"negation\" \n",
    "- the user's input sentence (that contains the negation) is concatenated thereafter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d6129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>negation</s></s> with the server because chances are, they probably forgot to punch it in and they will not even tell you that.</s><pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0, 23156, 1258, 2, 2, 19, 5, 10228, 142, 3255, 32, 6, 51, 1153, 18774, 7, 10064, 24, 11, 8, 51, 40, 45, 190, 1137, 47, 14, 4, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a10257",
   "metadata": {},
   "source": [
    "## AutoModelForQuestionAnswering\n",
    "- model architecture:\n",
    "    - BERT/BERT variants\n",
    "    - 2 classifier heads:\n",
    "        1. predict start token classifier\n",
    "        2. predict end token classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e01d8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f9adcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-squad\",\n",
    "    evaluation_strategy = \"epoch\",          # evaluation_strategy = \"epoch\" means to evaluate at the end of each epoch\n",
    "    # eval_steps = 100,                       # evaluate every n number of STEPS - steps = num samples/batch size\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    weight_decay = 0.002,\n",
    "    seed  = 0,\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d565759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c7eb8",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "- executes the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c50d1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e3ffe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/21 17:16:59 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 2:51:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.305700</td>\n",
       "      <td>0.802366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.727961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.758608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.823224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.803756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=0.5175093213717142, metrics={'train_runtime': 10399.1977, 'train_samples_per_second': 0.023, 'total_flos': 0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 16035840, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 2048618496, 'train_mem_cpu_peaked_delta': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64210e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9f8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc18d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5304c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
